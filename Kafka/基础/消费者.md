# 消费者

# 消费者组
Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制。
1. 组内可以有多个消费者或消费者实例，这里的实例可以是一个单独的进程，也可以是同一进程下的线程。
2. 它们共享一个公共的ID，这个ID被称为Group ID。它标识唯一的一个Consumer Group。
3. 组内的所有消费者协调在一起来消费订阅主题的所有分区，每个分区只能由同一个消费者组内的一个Consumer实例来消费。

Kafka仅仅使用Consumer Group这一种机制，却同时实现了传统消息引擎系统的两大模型：如果所有实例都属于同一个Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的Group，那么它实现的就是发布/订阅模型。

理想情况下，Consumer实例的数量应该等于该Group订阅主题的分区总数。

## 位移管理
对于Consumer Group而言，Offset是一组KV对，Key是分区，V对应Consumer消费该分区的最新位移。

* 老版本：把位移保存在ZooKeeper中，移保存在ZooKeeper外部系统的做法，减少了Kafka Broker端的状态保存开销，服务节点无状态这样可以自由地扩缩容，实现超强的伸缩性。
* 新版本：ZooKeeper这类元框架其实并不适合进行频繁的写更新，位移更新却是一个非常频繁的操作。重新设计，采用了将位移保存在Kafka内部主题的方法叫位移主题 。
### 位移主题 Offsets Topic
将Consumer的位移数据作为一条条普通的Kafka消息，提交到consumer_offsets中。consumer_offsets的主要作用是保存Kafka消费者的位移信息。

位移主题的Key中应该保存3部分内容：Group ID，主题名，Consumer要提交位移的分区号


当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题。
* 分区数：看Broker端参数offsets.topic.num.partitions的取值了。它的默认值是50
* 副本数：是Broker端参数offsets.topic.replication.factor，它的默认值是3。

Kafka Consumer提交位移时会写入该主题
* 自动提交：Consumer端有个参数叫enable.auto.commit，如果值是true，则Consumer在后台默默地为你定期提交位移，提交间隔由一个专属的参数auto.commit.interval.ms来控制。
* 手动提交：设置enable.auto.commit = false。Kafka Consumer API为你提供了位移提交的方法，如consumer.commitSync等。当调用这些方法时，Kafka会向位移主题写入相应的消息。

Kafka使用Compact策略删除位移主题中的过期消息，避免该主题无限期膨胀。
* Compact策略：扫描日志的所有消息，剔除那些过期的消息，保留最新发送的位移信息，然后把剩下的消息整理在一起。

Kafka提供了专门的后台线程定期地巡检待Compact的主题，看看是否存在满足条件的可删除数据。这个后台线程叫Log Cleaner。
## 重平衡
Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区。比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。
重平衡条件：
1. 组成员数发生变更。比如有新的Consumer实例加入组或者离开组
2. 订阅主题数发生变更。Consumer Group可以使用正则表达式的方式订阅主题
3. 订阅主题的分区数发生变更。

### 出现的问题
* 在Rebalance过程中，所有Consumer实例都会停止消费，等待Rebalance完成。
* 目前Rebalance的设计是所有Consumer实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。
* Rebalance太慢了
