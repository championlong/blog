# 消费者

# 消费者组
Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制。
1. 组内可以有多个消费者或消费者实例，这里的实例可以是一个单独的进程，也可以是同一进程下的线程。
2. 它们共享一个公共的ID，这个ID被称为Group ID。它标识唯一的一个Consumer Group。
3. 组内的所有消费者协调在一起来消费订阅主题的所有分区，每个分区只能由同一个消费者组内的一个Consumer实例来消费。

Kafka仅仅使用Consumer Group这一种机制，却同时实现了传统消息引擎系统的两大模型：如果所有实例都属于同一个Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的Group，那么它实现的就是发布/订阅模型。

理想情况下，Consumer实例的数量应该等于该Group订阅主题的分区总数。

## 位移管理
对于Consumer Group而言，Offset是一组KV对，Key是分区，V对应Consumer消费该分区的最新位移。

* 老版本：把位移保存在ZooKeeper中，移保存在ZooKeeper外部系统的做法，减少了Kafka Broker端的状态保存开销，服务节点无状态这样可以自由地扩缩容，实现超强的伸缩性。
* 新版本：ZooKeeper这类元框架其实并不适合进行频繁的写更新，位移更新却是一个非常频繁的操作。重新设计，采用了将位移保存在Kafka内部主题的方法叫位移主题 。
### 位移主题 Offsets Topic
将Consumer的位移数据作为一条条普通的Kafka消息，提交到consumer_offsets中。consumer_offsets的主要作用是保存Kafka消费者的位移信息。

位移主题的Key中应该保存3部分内容：Group ID，主题名，Consumer要提交位移的分区号


当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题。
* 分区数：看Broker端参数offsets.topic.num.partitions的取值了。它的默认值是50
* 副本数：是Broker端参数offsets.topic.replication.factor，它的默认值是3。

Kafka Consumer提交位移时会写入该主题
* 自动提交：Consumer端有个参数叫enable.auto.commit，如果值是true，则Consumer在后台默默地为你定期提交位移，提交间隔由一个专属的参数auto.commit.interval.ms来控制。
  * 开始调用poll方法时，提交上次poll返回的所有消息。从顺序上来说，poll方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。
  * 它可能会出现重复消费：默认情况下，Consumer每5秒自动提交一次位移。假设提交位移之后的3秒发生了Rebalance操作。在Rebalance之后，所有Consumer从上一次提交的位移处继续消费，但该位移已经是3秒前的位移数据了，故在Rebalance发生前3秒消费的所有数据都要重新再消费一次。
* 手动提交：设置enable.auto.commit = false。Kafka Consumer API为你提供了位移提交的方法，如consumer.commitSync等。当调用这些方法时，Kafka会向位移主题写入相应的消息。
  * 调用commitSync()时，Consumer程序会处于阻塞状态，直到远端的Broker返回提交结果，状态才会结束。会影响整个应用程序的TPS。
  * 调用commitAsync()之后，它会立即返回，不会阻塞，因此不会影响Consumer应用的TPS。Kafka提供了回调函数（callback），供你实现提交之后的逻辑，比如记录日志或处理异常等。但不能够替代commitSync因为出现问题时它不会自动重试。重试时提交的位移值可能早已经“过期”。
  * 同时使用了commitSync()和commitAsync()。对于常规性、阶段性的手动提交，我们调用commitAsync()避免程序阻塞，而在Consumer要关闭前，我们调用commitSync()方法执行同步阻塞式的位移提交，以确保Consumer关闭前能够保存正确的位移数据。
  * commitSync(Map)和commitAsync(Map)。参数是一个Map对象，键就是TopicPartition，即消费的分区，而值是一个OffsetAndMetadata对象，保存的主要是位移数据。创建一个Map对象，用于保存Consumer消费处理过程中要提交的分区位移，之后开始逐条处理消息，并构造要提交的位移值。然后就可以自定义消费多少消息进行提交。

Kafka使用Compact策略删除位移主题中的过期消息，避免该主题无限期膨胀。
* Compact策略：扫描日志的所有消息，剔除那些过期的消息，保留最新发送的位移信息，然后把剩下的消息整理在一起。

Kafka提供了专门的后台线程定期地巡检待Compact的主题，看看是否存在满足条件的可删除数据。这个后台线程叫Log Cleaner。
## 重平衡
Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区。比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。
重平衡条件：
1. 组成员数发生变更。比如有新的Consumer实例加入组或者离开组
2. 订阅主题数发生变更。Consumer Group可以使用正则表达式的方式订阅主题
3. 订阅主题的分区数发生变更。

### 出现的问题
* 在Rebalance过程中，所有Consumer实例都会停止消费，等待Rebalance完成。
* 目前Rebalance的设计是所有Consumer实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。
* Rebalance太慢了

### 避免问题

#### Coordinator
Coordinator，它专门为Consumer Group服务，负责为Group执行Rebalance以及提供位移管理和组成员管理等。Consumer端应用程序在提交位移时或Consumer应用启动时都是向Coordinator所在的Broker发送各种请求，然后由Coordinator负责执行消费者组的注册、成员管理记录等元数据管理操作。
所有Broker都有各自的Coordinator组件。

Consumer Group确定Coordinator所在的Broker的算法：
* 第1步：确定由位移主题的哪个分区来保存该Group数据，partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)
* 第2步：找出该分区Leader副本所在的Broker，该Broker即为对应的Coordinator。

Consumer实例都会定期地向Coordinator发送心跳请求，表明它还存活着。如果下线，从而将其从Group中移除，然后开启新一轮Rebalance。
* Consumer端有个参数，叫session.timeout.ms，就是被用来表征此事的。该参数的默认值是10秒，即如果Coordinator在10秒之内没有收到Group下某Consumer实例的心跳，它就会认为这个Consumer实例已经挂了。
* Consumer还提供了一个允许你控制发送心跳请求频率的参数，就是heartbeat.interval.ms。这个值设置得越小，Consumer实例发送心跳请求的频率就越高。
* Consumer端有参数用于控制Consumer实际消费能力对Rebalance的影响，即max.poll.interval.ms参数。它限定了Consumer端应用程序两次调用poll方法的最大时间间隔。它的默认值是5分钟，表示你的Consumer程序如果在5分钟之内无法消费完poll方法返回的消息，那么Consumer会主动发起“离开组”的请求，Coordinator也会开启新一轮Rebalance。


#### 不必要的Rebalance
* 非必要Rebalance是因为未能及时发送心跳，导致Consumer被“踢出”Group而引发的。因此，你需要仔细地设置session.timeout.ms（6s）和heartbeat.interval.ms（2s）的值。要保证Consumer实例在被判定为“dead”之前，能够发送至少3轮的心跳请求，即session.timeout.ms >= 3 * heartbeat.interval.ms。
* 非必要Rebalance是Consumer消费时间过长导致的。注意max.poll.interval.ms参数值的设置
* 关注Consumer端的GC表现，是否出现了频繁的Full GC导致的长时间停顿，从而引发了Rebalance。
