# Kafka
Apache Kafka是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）
## 术语

* 主题（Topic）：发布订阅的对象
* 生产者（Producer）：向主题发布消息的客户端应用程序
* 消费者（Consumer）：订阅这些主题消息的客户端应用程序
* 客户端（Clients）：生产者和消费者统称
* Broker： Kafka 服务器，一个Kafka集群由多个Broker组成。负责接收和处理客户端发送过来的请求，以及对消息进行持久化。
* 备份机制（Replication）：把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在Kafka中被称为副本。副本保存着相同的数据，但却有不同的角色和作用。
  * 领导者副本（Leader Replica）：与客户端程序进行交互，对外提供服务
  * 追随者副本（Follower Replica）：被动地追随领导者副本，不能与外界进行交互
  * 工作机制：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。
* 分区（Partitioning）：将每个主题划分成多个分区，每个分区是一组有序的消息日志。每条消息只会被发送到一个分区中。Kafka的分区编号是从0开始的。每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。
* 位移（Offset）：每条消息在分区中的位置信息，分区位移总是从0开始
* 消费者位移（Consumer Offset）：当前消费到了分区的哪个位置上
* 消息日志（Log）：Kafka Broker进行持久化通过日志实现，一个日志就是磁盘上一个只能追加写消息的物理文件。
* 日志段（Log Segment）：避免耗尽磁盘空间，Kafka底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
* 消费者组（Consumer Group）：点对点模型下，多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费。同时消费多个分区以实现高吞吐。
* 重平衡（Rebalance）：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance是Kafka消费者端实现高可用的重要手段

## 版本迭代
* 0.8 引入了副本机制。至此Kafka成为了一个真正意义上完备的分布式高可靠消息队列解决方案。
* 0.9.0.0 增加了基础的安全认证/权限功能，同时使用Java重写了新版本消费者API，另外还引入了Kafka Connect组件用于实现高性能的数据抽取。新版本Producer API在这个版本中算比较稳定了。但不要使用Consumer API，因为Bug多不完善。
* 0.10.0.0 引入了Kafka Streams。从这个版本起，Kafka正式升级成分布式流处理平台
* 0.10.2.2 可以使用新版本Consumer API。0.10.2.2修复了一个可能导致Producer性能降低的Bug。
* 0.11.0.0 一个是提供幂等性Producer API以及事务（Transaction） API；另一个是对Kafka消息格式做了重构。
* 1.0和2.0 两个大版本主要还是Kafka Streams的各种改进，在消息引擎方面并未引入太多的重大功能特性。

## 部署比对

### I/O
主流的I/O模型通常有5种类型：阻塞式I/O、非阻塞式I/O、I/O多路复用、信号驱动I/O和异步I/O。

Linux中系统调用select函数就属于I/O多路复用模型, epoll系统调用则介于第三种和第四种模型之间。第五种模型，其实很少有Linux系统支持，反而是Windows系统提供了一个叫IOCP线程模型属于这一种。

Kafka客户端底层使用了Java的selector，selector在Linux上的实现机制是epoll，而在Windows平台上的实现机制是select。因此在这一点上将Kafka部署在Linux上是有优势的，因为能够获得更高效的I/O性能。

### 网络传输效率
Kafka生产和消费的消息都是通过网络传输的，而消息保存在磁盘。Kafka需要在磁盘和网络间进行大量数据传输，Linux的零拷贝（Zero Copy）技术，就是当数据在磁盘和网络进行传输时避免昂贵的内核态数据拷贝从而实现快速的数据传输。在Linux部署Kafka能够享受到零拷贝技术所带来的快速数据传输特性。

### 磁盘
Kafka使用机械硬盘就可以

原因：Kafka虽大量使用磁盘，但使用方式多是顺序读写，一定程度上规避了机械磁盘最大的劣势，即随机读写操作慢。

### 磁盘容量
规划磁盘容量时你需要考虑下面这几个元素：
* 新增消息数
* 消息留存时间
* 平均消息大小
* 备份数
* 是否启用压缩

### 带宽
Kafka这种通过网络大量进行数据传输的框架而言，带宽特别容易成为瓶颈。

假设平时使用的都是普通的以太网络，带宽也主要有两种：1Gbps的千兆网络和10Gbps的万兆网络，这里用以千兆网络举举例。
> 业务目标是在1小时内处理1TB的业务数据

带宽是1Gbps，即每秒处理1Gb的数据，Kafka会用到70%的带宽资源（超过70%的阈值就有网络丢包的可能性了），单台Kafka服务器最多也就能使用大约700Mb。常规模式下要再额外预留出2/3的资源，即单台服务器使用带宽700Mb / 3 ≈ 240Mbps。1小时处理1Td的数据约等于需要10台服务器。如果消息还需要额外复制两份，那么总的服务器台数还要乘以3，即30台。

# Kafka拦截器
Kafka拦截器分为生产者拦截器和消费者拦截器
* 生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑
* 消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。
## 设置方法
参数配置 interceptor.classes，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。指定拦截器类时要指定它们的全限定名
## 使用场景
Kafka拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。