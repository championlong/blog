# Broker端参数

静态参数：在Kafka的配置文件server.properties中进行设置的参数，必须重启Broker进程才能令它们生效。

## 存储信息相关参数
* log.dirs：指定了Broker需要使用的若干个文件目录路径。要知道这个参数是没有默认值的，它必须由你亲自指定。
* log.dir：只能表示单个路径，是补充上一个参数用的。

`log.dirs` 配置方式类似/home/kafka1,/home/kafka2,/home/kafka3。有条件的话最好保证这些目录挂载到不同的物理磁盘上。好处：
* 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
* 能够实现故障转移：即Failover。这是Kafka 1.1版本新引入的强大功能。在以前，只要Kafka Broker使用的任何一块磁盘挂掉了，整个Broker进程都会关闭。但是自1.1开始，这种情况被修正了，坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且Broker还能正常工作。

## ZooKeeper相关设置

ZooKeeper作用：是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行、创建了哪些Topic，每个Topic都有多少分区以及这些分区的Leader副本都在哪些机器上等信息。
* zookeeper.connect：配置方式csv格式参数，zk1:2181,zk2:2181,zk3:2181。如果多个Kafka集群使用同一套ZooKeeper集群，可以利用chroot配置，zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2。

## Broker链接相关
客户端程序或其他Broker如何与该Broker进行通信的设置。
* listeners：听器，告诉外部连接者要通过什么协议访问指定主机名和端口开放的Kafka服务。 
  * 三元组参数格式，<协议名称，主机名，端口号>
* advertised.listeners：和listeners相比多了个advertised。Advertised的含义表示宣称的、公布的，就是说这组监听器是Broker用于对外发布的。
* host.name/port：列出这两个参数就是想说你把它们忘掉吧，压根不要为它们指定值，毕竟都是过期的参数了。

## Topic管理相关
* auto.create.topics.enable：是否允许自动创建Topic。
* unclean.leader.election.enable：是否允许Unclean Leader选举
  * 设置成false：如果保存数据比较多的副本都挂了，则坚持原则，坚决不能让保存数据落后的副本竞选Leader。分区就不可用了
  * true：允许你从那些“跑得慢”的副本中选一个出来当Leader。这样做的后果是数据有可能就丢失了
* auto.leader.rebalance.enable：是否允许定期进行Leader选举。
  * true：表示允许Kafka定期地对一些Topic分区进行Leader重选举
  * false：这种换Leader本质上没有任何性能收益，代价还高，因此建议你=在生产环境中把这个参数设置成false。


## 数据留存相关参数

* log.retention.{hours|minutes|ms}：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说ms设置最高、minutes次之、hours最低。
  * log.retention.hours=168表示默认保存7天的数据
* log.retention.bytes：这是指定Broker为消息保存的总磁盘容量大小。
  * 这个值默认是-1，表明你想在这台Broker上保存多少数据都可以，至少在容量方面Broker绝对为你开绿灯，不会做任何阻拦。
* message.max.bytes：控制Broker能够接收的最大消息大小。
  * 默认的1000012太少了，还不到1MB。实际场景中突破1MB的消息都是屡见不鲜的，因此在线上环境中设置一个比较大的值还是比较保险的做法。

# Topic级别参数
Topic级别参数会覆盖全局Broker参数的值，而每个Topic都能设置自己的参数值

## 保存消息方面
* retention.ms：规定了该Topic消息被保存的时长。默认是7天
* retention.bytes：规定了要为该Topic预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的Kafka集群中会有用武之地。当前默认值是-1，表示可以无限使用磁盘空间。
* max.message.bytes：设置最大消息数

## 修改topic参数方法

```shell
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760
```

# JVM参数
* KAFKA_HEAP_OPTS：指定堆大小。默认的1GB有点小, 设置成6GB，这是目前业界比较公认的一个合理值。Kafka Broker在与客户端进行交互时会在JVM堆上创建大量的ByteBuffer实例，Heap Size不能太小。
* KAFKA_JVM_PERFORMANCE_OPTS：Java 8，那么可以手动设置使用G1收集器
  
设置方式
```shell
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

# 操作系统参数
* 文件描述符限制：ulimit -n。通常情况下将它设置成一个超大的值是合理的做法
* 文件系统类型：生产环境最好还是使用XFS日志型文件系统。
* Swappiness：一旦设置成0，当物理内存耗尽时，操作系统会触发OOM killer这个组件，它会随机挑选一个进程然后kill掉，即根本不给用户任何的预警。但如果设置成一个比较小的值，当开始使用swap空间时，你至少能够观测到Broker性能开始出现急剧下降，从而给你进一步调优和诊断问题的时间。
* 提交时间：默认是5秒。Kafka只要数据被写入到操作系统的页缓存就认为写入磁盘成功了，随后操作系统根据LRU算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。可以适当地增加提交间隔来降低物理磁盘的写操作。Kafka在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。