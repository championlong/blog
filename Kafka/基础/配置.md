# Broker端参数

静态参数：在Kafka的配置文件server.properties中进行设置的参数，必须重启Broker进程才能令它们生效。

## 存储信息相关参数
* log.dirs：指定了Broker需要使用的若干个文件目录路径。要知道这个参数是没有默认值的，它必须由你亲自指定。
* log.dir：只能表示单个路径，是补充上一个参数用的。

`log.dirs` 配置方式类似/home/kafka1,/home/kafka2,/home/kafka3。有条件的话最好保证这些目录挂载到不同的物理磁盘上。好处：
* 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
* 能够实现故障转移：即Failover。这是Kafka 1.1版本新引入的强大功能。在以前，只要Kafka Broker使用的任何一块磁盘挂掉了，整个Broker进程都会关闭。但是自1.1开始，这种情况被修正了，坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且Broker还能正常工作。

## ZooKeeper相关设置

ZooKeeper作用：是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行、创建了哪些Topic，每个Topic都有多少分区以及这些分区的Leader副本都在哪些机器上等信息。
* zookeeper.connect：配置方式csv格式参数，zk1:2181,zk2:2181,zk3:2181。如果多个Kafka集群使用同一套ZooKeeper集群，可以利用chroot配置，zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2。

## Broker链接相关
客户端程序或其他Broker如何与该Broker进行通信的设置。
* listeners：听器，告诉外部连接者要通过什么协议访问指定主机名和端口开放的Kafka服务。 
  * 三元组参数格式，<协议名称，主机名，端口号>
* advertised.listeners：和listeners相比多了个advertised。Advertised的含义表示宣称的、公布的，就是说这组监听器是Broker用于对外发布的。
* host.name/port：列出这两个参数就是想说你把它们忘掉吧，压根不要为它们指定值，毕竟都是过期的参数了。

## Topic管理相关
* auto.create.topics.enable：是否允许自动创建Topic。
* unclean.leader.election.enable：是否允许Unclean Leader选举
  * 设置成false：如果保存数据比较多的副本都挂了，则坚持原则，坚决不能让保存数据落后的副本竞选Leader。分区就不可用了
  * true：允许你从那些“跑得慢”的副本中选一个出来当Leader。这样做的后果是数据有可能就丢失了
* auto.leader.rebalance.enable：是否允许定期进行Leader选举。
  * true：表示允许Kafka定期地对一些Topic分区进行Leader重选举
  * false：这种换Leader本质上没有任何性能收益，代价还高，因此建议你=在生产环境中把这个参数设置成false。


## 数据留存相关参数

* log.retention.{hours|minutes|ms}：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说ms设置最高、minutes次之、hours最低。
  * log.retention.hours=168表示默认保存7天的数据
* log.retention.bytes：这是指定Broker为消息保存的总磁盘容量大小。
  * 这个值默认是-1，表明你想在这台Broker上保存多少数据都可以，至少在容量方面Broker绝对为你开绿灯，不会做任何阻拦。
* message.max.bytes：控制Broker能够接收的最大消息大小。
  * 默认的1000012太少了，还不到1MB。实际场景中突破1MB的消息都是屡见不鲜的，因此在线上环境中设置一个比较大的值还是比较保险的做法。

# Topic级别参数
Topic级别参数会覆盖全局Broker参数的值，而每个Topic都能设置自己的参数值

## 保存消息方面
* retention.ms：规定了该Topic消息被保存的时长。默认是7天
* retention.bytes：规定了要为该Topic预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的Kafka集群中会有用武之地。当前默认值是-1，表示可以无限使用磁盘空间。
* max.message.bytes：设置最大消息数

## 修改topic参数方法

```shell
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760
```

# JVM参数
* KAFKA_HEAP_OPTS：指定堆大小。默认的1GB有点小, 设置成6GB，这是目前业界比较公认的一个合理值。Kafka Broker在与客户端进行交互时会在JVM堆上创建大量的ByteBuffer实例，Heap Size不能太小。
* KAFKA_JVM_PERFORMANCE_OPTS：Java 8，那么可以手动设置使用G1收集器
  
设置方式
```shell
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

# 操作系统参数
* 文件描述符限制：ulimit -n。通常情况下将它设置成一个超大的值是合理的做法
* 文件系统类型：生产环境最好还是使用XFS日志型文件系统。
* Swappiness：一旦设置成0，当物理内存耗尽时，操作系统会触发OOM killer这个组件，它会随机挑选一个进程然后kill掉，即根本不给用户任何的预警。但如果设置成一个比较小的值，当开始使用swap空间时，你至少能够观测到Broker性能开始出现急剧下降，从而给你进一步调优和诊断问题的时间。
* 提交时间：默认是5秒。Kafka只要数据被写入到操作系统的页缓存就认为写入磁盘成功了，随后操作系统根据LRU算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。可以适当地增加提交间隔来降低物理磁盘的写操作。Kafka在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。

# 无消息丢失
* Kafka只对“已提交”的消息（committed message）做有限度的持久化保证。
* 有限度的持久化保证: 前提条件就是这N个Broker中至少有1个存活。

## 案例

### 生产者程序丢失数据
Kafka Producer是异步发送消息的，如果你调用的是producer.send(msg)这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。

没提交成功可能的原因
* 网络抖动，Broker没有收到消息
* 消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等

解决方案

Producer永远要使用带有回调通知的发送API，也就是说不要使用producer.send(msg)，而要使用producer.send(msg, callback)。callback能准确地告诉你消息是否真的提交成功了。
### 消费者程序丢失数据
1. Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。如果先更新位移，再读就可能会出现问题。
2. Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。
解决方案

1. 维持先消费消息（阅读），再更新位移（书签）的顺序即可。但这种处理方式可能带来的问题是消息的重复处理。
2. 如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移。

## 配置
1. 使用producer.send(msg, callback)。
2. 设置acks = all。acks是Producer的一个参数，代表了你对“已提交”消息的定义。如果设置成all，则表明所有副本Broker都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。
3. 设置retries为一个较大的值。是Producer的参数，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了retries > 0的Producer能够自动重试消息发送，避免消息丢失。
4. 设置unclean.leader.election.enable = false。是Broker端的参数，它控制的是哪些Broker有资格竞选分区的Leader。如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失。该参数设置成false，即不允许这种情况的发生。
5. 设置replication.factor >= 3。是Broker端的参数。将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。
6. 设置min.insync.replicas > 1。是Broker端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于1可以提升消息持久性。
7. 确保replication.factor > min.insync.replicas。两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成replication.factor = min.insync.replicas + 1。
8. Consumer端有个参数enable.auto.commit，最好把它设置成false，并采用手动提交位移的方式。


