
# PostreSQL

> Native破解：<https://macwk.com/soft/navicat-premium>
> sqlpro studio

## 备份相关

*   导出excel:\COPY (SELECT * FROM table where id = '') TO '/home/chenglong/name.csv' WITH csv;

#### pg_dump

*   备份sql：PGPASSWORD='' pg_dump -h localhost -U postgres -d 'databases' -p 5432 -a > test1.sql

*   导入sql：PGPASSWORD='' psql -h localhost -U postgres -d 'databases' -p 5432 <test.sql

*   备份单个表的sql：pg_dump -h localhost -p 5432 -U postgres -t tableName databases > tableName.sql

*   备份表信息数据：pg_dump -h localhost -U postgres -d 'databases' -p 5432   --table=tableName --inserts --column-inserts --encoding=UTF8 --disable-dollar-quoting --file=tableName.sql

*   使用数据库命令：psql -U postgres -h localhost -p 5432 -d databases

*   UTC时间转换：to_char(created_time at time zone 'UTC+8', 'YYYY-MM-DD')

*   分时查询相关：

```sql
select to_char(created_time AT time zone 'UTC', 'yyyy-mm-dd:HH24') as time,count(*) from table group by to_char(created_time AT time zone 'UTC', 'yyyy-mm-dd:HH24');
```

*   查看数据库表信息：

```sql
select a.attnum AS "序号",
c.relname AS "表名",
cast(obj_description(relfilenode,'pg_class') as varchar) AS "表名描述",
a.attname AS "列名",
concat_ws('',t.typname,SUBSTRING(format_type(a.atttypid,a.atttypmod) from '(.*)')) as "字段类型",
d.description AS "备注"
from pg_class c, pg_attribute a , pg_type t, pg_description d
where c.relname = '表名'
and a.attnum>0
and a.attrelid = c.oid
and a.atttypid = t.oid
and d.objoid=a.attrelid
and d.objsubid=a.attnum
ORDER BY c.relname DESC,a.attnum ASC
```

### 常用命令

*   查看已经存在的数据库：\l
*   使用数据库：\c + 数据库名
*   配置后查询不需要表名前添加模式：ALTER ROLE postgres SET search_path = yay,public;
*   查询表大小：select pg_size_pretty(pg_total_relation_size('test'));

## SQL

*   排序null值在后 select * from tableName order by id nulls last;
*   判断值是否在数组中：select * from 表名 where '' = any(字段名)
*   查询数组：SELECT * FROM contacts WHERE '(408)-589-5555' = ANY (phones);

> 在关系数据库中，术语upsert被称为合并(merge)。意思是，当执行 INSERT操作时，如果数据表中不存在对应的记录，PostgreSQL执行插入操作；如果数据表中存在对应的记录，则执行更新操作。

> 通过 INSERT ON CONFLICT 来使用 upsert 功能：

*   创建用户：

    CREATE USER dbuser WITH PASSWORD '<CUSTOM PASSWORD>';
*   设置默认模式：SET search_path TO myschema,public;
*   在线创建索引，不会阻塞：CREATE UNIQUE INDEX CONCURRENTLY on  table(column1, column2);
*   DROP INDEX  CONCURRENTLY unique_key;
*   upsert相关

```sql
-- upsert更新，更新值时涉及多个的app_names = EXCLUDED.app_names
INSERT INTO tableName (insertColumnStr) VALUES (insertQuestionMarks) ON CONFLICT upsertIndexStr DO UPDATE SET updateStr RETURNING id
-- upsert不更新
INSERT INTO tableName (insertColumnStr) VALUES (insertQuestionMarks) ON CONFLICT upsertIndexStr DO NOTHING
```

*   数组相关：<http://www.postgres.cn/docs/9.4/functions-array.html>

```sql
array_append：向数组尾部添加元素；
array_cat：拼接两个数组；
array_remove：删除某个元素；
array_replace：替换某个元素；
tags @> '{test}'：是否包含某个元素；
array_to_string：数组以特定连接符连接并且以字符串形式返回；

-- 查找
SELECT name, phones FROM contacts WHERE '(408)-589-5555' = ANY (phones);

select name from contacts where array_to_string(phones,',') like '%1722010887%';

select * from track_info_region where phones && array[202183271346::bigint] ;

-- 数组追加
update t_kenyon set items = items||7;
UPDATE 1
select * from t_kenyon;id |  items 
----+---------
  1 | {1,2,7}
(1 row)

update t_kenyon set items = items||'{99,66}';
UPDATE 1
select * from t_kenyon;
id |      items      
----+------------------
  1 | {1,2,7,55,99,66}
(1 row)

# 往前插
update t_kenyon set items = array_prepend(55,items) ;
UPDATE 1
select * from t_kenyon;
id |        items       
----+---------------------
  1 | {55,1,2,7,55,99,66}
(1 row)
```

*   枚举类型：

```sql
-- 创建枚举
create type admin_level1 as enum('classifier', 'moderator', 'god');
-- 查看枚举
SELECT enum_range(NULL::列名);

-- 查询枚举类型的pid
select * from pg_type where typname = 'delivery_type';

-- 查询枚举类型的所有定义(pg_type 的oid 作为 pg_enum的enumtypid)
SELECT * FROM pg_enum where enumtypid = 871653;

-- 枚举类型中增加新的枚举值
ALTER TYPE type_name ADD VALUE 'xx';

-- 删除枚举类型
drop type type_name;
```

*   联合唯一索引

```sql
ALTER TABLE ONLY 表名  ADD CONSTRAINT 索引名称 UNIQUE (列, 列);
```

### 工具SQL

*   查询表大小

```sql
select relname, (table_size/rows + index_size)::bigint as table_raw, pg_size_pretty(table_size/rows + index_size) as total_size, ((table_size/rows + index_size)::numeric/10.24/(2500*1024)/1024)::numeric(8,2) as rate,
       pg_size_pretty(table_size/rows) as table_size,
       pg_size_pretty(index_size) as index_size
from (
         select relname,
                sum(pg_relation_size(relid) ) as table_size,
                sum(pg_relation_size(indexrelid) ) as index_size,
                count(1) AS rows
         from pg_stat_user_indexes
         group by relname
     ) a
where table_size>500*1024*1024 
order by table_size/rows + index_size desc;
```

## 错误

### 启动失败

进入目录：cd /Users/<user_name>/Library/Application\ Support/Postgres/var-版本
删除文件：postmaster.pid
重启服务

## 慢查询

查询索引：EXPLAIN ANALYZE

### 问题1

只使用ORDER BY id时，和只使用LIMIT 1时，秒查

同时使用ORDER BY id和LIMIT 1时，查询超时

#### 解释

*   只使用LIMIT 1时：会通过idfv索引找到符合条件的行，然后读取整行数据，返回
*   同时使用ORDER BY和LIMIT 1时：正常来说应该时先按idfv找行，然后读取整行的数据，按id排序，返回第一个

    *   pg可能会觉得消耗很多，既然只需要一行数据，就进行如下优化：
    *   先按id排序，然后向下找，判断idfv是否符合条件，只要找到一行就返回
    *   然而在该idfv不存在的情况下，这会导致对全表的查找

#### 解决方案

1.  将LIMIT 1 改成 LIMIT 2
2.  去掉LIMIT，在程序里做TopN逻辑
3.  建立(idfv, id)索引
4.  ORDER BY一个没有索引的列
5.  上述任意一个都可以解决

### 问题2

exist函数执行时由于涉及计算耗CPU，导致CPU飙升

#### 解决方案

1.  在查询qps较高的情况下尽量不要使用函数
2.  类似业务，进入第二天之后缓存失效的情况下如果qps很高，需要考虑通过kafka削峰，或者对缓存的失效时间加随机数，在进入0点一段时间后使key失效
3.  线上qps较高的服务应当做降级策略
4.  将查询sql改写，不再使用exist函数，直接select 1
5.  可以考虑用令牌池+kafka的方案进行削峰，能拿到令牌的情况下，起协程对活跃消息进行处理，无令牌情况下则写入kafka另起协程消费
6.  可以考虑在接近0点的时候同时set一部分key到第二天的key上，value记为1，第二天时候发现如果key存在，则value + 1，=2的情况下会再进行归因

## 分布式

支持extension插件扩展，不像mysql的proxy局限性很大。包括计算下推、